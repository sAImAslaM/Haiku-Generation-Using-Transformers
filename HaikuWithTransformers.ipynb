{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obhRqry_gQYN"
      },
      "source": [
        "# Submitted By:\n",
        "### Asad Tariq 19I-0659\n",
        "### Abdullah Abbasi 19I-2179\n",
        "### Saim Aslam 19I-0461"
      ],
      "id": "obhRqry_gQYN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d25648e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import datetime\n",
        "import time\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import json\n",
        "from pathlib import Path\n",
        "import re\n",
        "import random\n",
        "import inflect\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "id": "3d25648e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAxvCTgsub-7",
        "outputId": "382d8618-83e5-4de2-8a8a-3c75fdbab7db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ],
      "id": "rAxvCTgsub-7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c92e5123"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup"
      ],
      "id": "c92e5123"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b679d1d0",
        "outputId": "3aec4dcd-c637-4a9f-a3c0-1c1266a2a96f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 2.0.0+cu118\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, jinja2, networkx, sympy, triton, typing-extensions\n",
            "Required-by: fastai, torchaudio, torchdata, torchtext, torchvision, triton\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(64)\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "!pip show torch"
      ],
      "id": "b679d1d0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04d66abb",
        "outputId": "912b41b1-4645-4695-89bb-a2e3a68b2af3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "id": "04d66abb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0ry-rO1vCq_",
        "outputId": "8fcba6e2-8996-4c2c-8b99-670260cb2512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "N0ry-rO1vCq_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d55fa70"
      },
      "outputs": [],
      "source": [
        "\n",
        "nRowsRead = None # specify 'None' if want to read whole file\n",
        "#df = pd.read_csv('INPUT/all_haiku.csv', delimiter=',', nrows = nRowsRead)\n",
        "df=pd.read_csv('/content/gdrive/MyDrive/Work/all_haiku.csv')"
      ],
      "id": "0d55fa70"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75246fc8",
        "outputId": "61fd496f-1860-4ab4-a05e-d2421fb1e8fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 144123 rows and 6 columns\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df.dataframeName = 'all_haiku.csv'\n",
        "nRow, nCol = df.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "id": "75246fc8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccbbdb0e"
      },
      "outputs": [],
      "source": [
        "df=df.drop('Unnamed: 0',axis=1)\n",
        "df=df.drop('source',axis=1)\n",
        "df=df.drop('hash',axis=1)"
      ],
      "id": "ccbbdb0e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cd8668b"
      },
      "outputs": [],
      "source": [
        "df[\"2\"] = df[\"2\"].astype(str)\n",
        "df[\"2\"] = [x.replace('-','') for x in df[\"2\"]]\n",
        "df = df.replace('[^\\w\\s]', '')\n",
        "df = df.replace('-','',regex=True)\n",
        "df.rename(columns = {'0':0,'1':1,'2':2}, inplace = True)"
      ],
      "id": "9cd8668b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "a2835278",
        "outputId": "ceafd6f3-a0e1-4281-9b09-1f622146d3c6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c9fa5b46-d30d-4a33-9f93-71458bef5d81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fishing boats</td>\n",
              "      <td>colors of</td>\n",
              "      <td>the rainbow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ash wednesday</td>\n",
              "      <td>trying to remember</td>\n",
              "      <td>my dream</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>snowy morn</td>\n",
              "      <td>pouring another cup</td>\n",
              "      <td>of black coffee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>shortest day</td>\n",
              "      <td>flames dance</td>\n",
              "      <td>in the oven</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>haze</td>\n",
              "      <td>half the horse hidden</td>\n",
              "      <td>behind the house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>low sun</td>\n",
              "      <td>the lady in red</td>\n",
              "      <td>on high heels</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>advent</td>\n",
              "      <td>the passing stranger</td>\n",
              "      <td>farts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tarn</td>\n",
              "      <td>a bubble in</td>\n",
              "      <td>the ice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>snowflakes</td>\n",
              "      <td>new asphalt</td>\n",
              "      <td>in the holes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Crystal Night'</td>\n",
              "      <td>gusts of rain</td>\n",
              "      <td>outside</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>rain</td>\n",
              "      <td>the sound of a horse galloping</td>\n",
              "      <td>through leaves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>winter stars</td>\n",
              "      <td>suddenly a whiff</td>\n",
              "      <td>of perfume</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>hungry</td>\n",
              "      <td>half of the moon</td>\n",
              "      <td>hidden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>rain</td>\n",
              "      <td>another leaf</td>\n",
              "      <td>down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sharia</td>\n",
              "      <td>the sound of one hand</td>\n",
              "      <td>clapping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>the sound of geese</td>\n",
              "      <td>drowned by the sound of the train</td>\n",
              "      <td>this morning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>autumn sun</td>\n",
              "      <td>my shadow over</td>\n",
              "      <td>tombstones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>fly fishing;</td>\n",
              "      <td>the sound of the wind</td>\n",
              "      <td>in the reel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>december</td>\n",
              "      <td>a long shadow</td>\n",
              "      <td>joins another</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>end of path</td>\n",
              "      <td>snowflakes melting</td>\n",
              "      <td>on the pond</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9fa5b46-d30d-4a33-9f93-71458bef5d81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9fa5b46-d30d-4a33-9f93-71458bef5d81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9fa5b46-d30d-4a33-9f93-71458bef5d81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     0                                  1                 2\n",
              "0        fishing boats                          colors of       the rainbow\n",
              "1        ash wednesday                trying to remember           my dream\n",
              "2           snowy morn                pouring another cup   of black coffee\n",
              "3         shortest day                       flames dance       in the oven\n",
              "4                 haze              half the horse hidden  behind the house\n",
              "5              low sun                    the lady in red     on high heels\n",
              "6               advent               the passing stranger             farts\n",
              "7                 tarn                        a bubble in           the ice\n",
              "8           snowflakes                        new asphalt      in the holes\n",
              "9       Crystal Night'                      gusts of rain           outside\n",
              "10                rain     the sound of a horse galloping    through leaves\n",
              "11        winter stars                   suddenly a whiff        of perfume\n",
              "12              hungry                   half of the moon            hidden\n",
              "13                rain                       another leaf              down\n",
              "14              sharia              the sound of one hand          clapping\n",
              "15  the sound of geese  drowned by the sound of the train      this morning\n",
              "16          autumn sun                     my shadow over        tombstones\n",
              "17        fly fishing;              the sound of the wind       in the reel\n",
              "18            december                      a long shadow     joins another\n",
              "19         end of path                 snowflakes melting       on the pond"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(20)"
      ],
      "id": "a2835278"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acfa3855"
      },
      "outputs": [],
      "source": [
        "input_list=[]\n",
        "#for i in range(144123):\n",
        "for i in range(10000):\n",
        "    input_list.append(df[0][i]+'\\n'+df[1][i]+'\\n'+df[2][i]+'.')"
      ],
      "id": "acfa3855"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "457100a6",
        "outputId": "c34a750d-1722-42b2-a7d8-d9ad2e8c8405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fishing boats\n",
            "colors of\n",
            "the rainbow.\n"
          ]
        }
      ],
      "source": [
        "print(input_list[0])"
      ],
      "id": "457100a6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdf527e1"
      },
      "outputs": [],
      "source": [
        "class HaikuDataset(Dataset):\n",
        "  def __init__(self, haikus, tokenizer, max_length=25, gpt2_type=\"gpt2\"):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for haiku in haikus:\n",
        "\n",
        "      encodings_dict = tokenizer(\"<|startoftext|>\"+haiku+\"<|endoftext|>\",\n",
        "                                 truncation=True,\n",
        "                                 max_length=max_length,\n",
        "                                 padding=\"max_length\")\n",
        "      \n",
        "      self.input_ids.append(torch.tensor(encodings_dict[\"input_ids\"]))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict[\"attention_mask\"]))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx]"
      ],
      "id": "fdf527e1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaec927f",
        "outputId": "ca825ddf-d6b9-49a8-c2ee-822fb34df9af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Loading GPT2 Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
        "                                          bos_token='<|startoftext|>', \n",
        "                                          eos_token='<|endoftext|>', \n",
        "                                          pad_token='<|pad|>')"
      ],
      "id": "aaec927f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cad46897",
        "outputId": "7eea04d8-8cd9-4f94-c21d-91f5485f62ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[50257, 18435, 2159, 220, 50256, 50258, 50258, 50258, 50258, 50258]\n",
            "50259\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.encode(\"<|startoftext|> Hello World <|endoftext|>\", padding=\"max_length\", max_length=10))\n",
        "print(len(tokenizer))"
      ],
      "id": "cad46897"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abd13398",
        "outputId": "c6b56ba8-ba91-4869-a4eb-c799219cfd53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n"
          ]
        }
      ],
      "source": [
        "# Finding length of maximum token in dataset\n",
        "max_length = max([len(tokenizer.encode(haiku)) for haiku in input_list])\n",
        "print(max_length)\n",
        "max_length = 25"
      ],
      "id": "abd13398"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71b67b30"
      },
      "outputs": [],
      "source": [
        "x = [len(tokenizer.encode(haiku)) for haiku in input_list if len(tokenizer.encode(haiku)) < 100]"
      ],
      "id": "71b67b30"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e28ddb91"
      },
      "outputs": [],
      "source": [
        "y = [len(tokenizer.encode(haiku)) - len(haiku.split()) for haiku in input_list]"
      ],
      "id": "e28ddb91"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67c4592b",
        "outputId": "0579dbe6-597f-4f39-c456-0d5273428301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.7489\n"
          ]
        }
      ],
      "source": [
        "print(sum(y)/len(y))"
      ],
      "id": "67c4592b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "e0fd9eb6",
        "outputId": "9d62e599-c276-4cd3-ed18-b09bdf20b4d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "98 9950\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(max(x), len(x))\n",
        "plt.hist(x, bins = 5)\n",
        "plt.show"
      ],
      "id": "e0fd9eb6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fb5b1ee"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "max_length = 25"
      ],
      "id": "5fb5b1ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3e4edb7",
        "outputId": "498ab042-7dd7-40d8-f844-cbfee2610c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples for training = 9000\n",
            "Number of samples for validation = 1000\n"
          ]
        }
      ],
      "source": [
        "dataset = HaikuDataset(input_list, tokenizer, max_length=max_length)\n",
        "\n",
        "# Split data into train and validation sets\n",
        "train_size = int(0.9*len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "print(\"Number of samples for training =\", train_size)\n",
        "print(\"Number of samples for validation =\", val_size)"
      ],
      "id": "d3e4edb7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "907e5ff7",
        "outputId": "00d51387-ab6b-43f6-fe87-8987b2b30959"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([50257,   270, 35737,   355,   673,  1364,   198,   392,  3332, 30819,\n",
              "          2945,   416, 16252,   198,    86,   623,  1586,    13, 50256, 50258,\n",
              "         50258, 50258, 50258, 50258, 50258]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "         0]))"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]"
      ],
      "id": "907e5ff7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44394442"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              sampler=RandomSampler(train_dataset),\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "val_dataloader = DataLoader(val_dataset,\n",
        "                            sampler=SequentialSampler(val_dataset),\n",
        "                            batch_size=batch_size)"
      ],
      "id": "44394442"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71e0d018"
      },
      "outputs": [],
      "source": [
        "# Load model configuration\n",
        "config = GPT2Config.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Create model instance and set embedding length\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=config)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Running the model on GPU\n",
        "model = model.to(device)"
      ],
      "id": "71e0d018"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "091999e7"
      },
      "outputs": [],
      "source": [
        "# Setting seeds to enable reproducible runs\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "id": "091999e7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61a66f28"
      },
      "outputs": [],
      "source": [
        "epochs = 6\n",
        "warmup_steps = 1e2\n",
        "sample_every = 1000"
      ],
      "id": "61a66f28"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "622ef68a",
        "outputId": "ce6e0dd2-a994-43bd-a0fe-a1998b82edaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "900\n",
            "9000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataloader))\n",
        "print(len(train_dataset))"
      ],
      "id": "622ef68a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "166b4e87"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-4, eps=1e-8)\n",
        "\n",
        "# Toatl training steps is the number of data points times the number of epochs\n",
        "total_training_steps = len(train_dataloader)*epochs\n",
        "\n",
        "# Setting a variable learning rate using scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=warmup_steps,\n",
        "                                            num_training_steps=total_training_steps)"
      ],
      "id": "166b4e87"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd2075a9"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "  return str(datetime.timedelta(seconds=int(round(elapsed))))"
      ],
      "id": "cd2075a9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "27453737",
        "outputId": "9e0556cd-015b-4c0f-849c-0fc3a7847776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning epoch 1 of 6\n",
            "Average Training Loss: 4.219348088635338. Epoch time: 0:01:40\n",
            "\n",
            "Validation loss: 3.4010601162910463. Validation Time: 0:00:03\n",
            "\n",
            "------------------------------\n",
            "Beginning epoch 2 of 6\n",
            "Average Training Loss: 2.9972355830669404. Epoch time: 0:01:37\n",
            "\n",
            "Validation loss: 3.463474953174591. Validation Time: 0:00:02\n",
            "\n",
            "------------------------------\n",
            "Beginning epoch 3 of 6\n",
            "Average Training Loss: 2.489995809925927. Epoch time: 0:01:37\n",
            "\n",
            "Validation loss: 3.6750632429122927. Validation Time: 0:00:02\n",
            "\n",
            "------------------------------\n",
            "Beginning epoch 4 of 6\n",
            "Average Training Loss: 1.9165501974688637. Epoch time: 0:01:37\n",
            "\n",
            "Validation loss: 4.090302004814148. Validation Time: 0:00:03\n",
            "\n",
            "------------------------------\n",
            "Beginning epoch 5 of 6\n",
            "Average Training Loss: 1.3673061731126572. Epoch time: 0:01:37\n",
            "\n",
            "Validation loss: 4.745888497829437. Validation Time: 0:00:03\n",
            "\n",
            "------------------------------\n",
            "Beginning epoch 6 of 6\n",
            "Average Training Loss: 0.9758861374855041. Epoch time: 0:01:37\n",
            "\n",
            "Validation loss: 5.2002828145027165. Validation Time: 0:00:02\n",
            "\n",
            "------------------------------\n",
            "Total training took 0:10:01\n"
          ]
        }
      ],
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(epochs):\n",
        "  print(f'Beginning epoch {epoch_i+1} of {epochs}')\n",
        "\n",
        "  t0 = time.time()\n",
        "  total_train_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  # Labels are shifted by 1 timestep\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[0].to(device)\n",
        "    b_masks = batch[1].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    outputs = model(b_input_ids,\n",
        "                    labels=b_labels,\n",
        "                    attention_mask=b_masks)\n",
        "    \n",
        "    loss = outputs[0]\n",
        "\n",
        "    batch_loss = loss.item()\n",
        "    total_train_loss += batch_loss\n",
        "\n",
        "    # Sampling every x steps\n",
        "    if step != 0 and step % sample_every == 0:\n",
        "\n",
        "      elapsed = format_time(time.time()-t0)\n",
        "      print(f'Batch {step} of {len(train_dataloader)}. Loss: {batch_loss}. Time: {elapsed}')\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 25,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "      for i, sample_output in enumerate(sample_outputs):\n",
        "        print(f'Example ouput: {tokenizer.decode(sample_output, skip_special_tokens=True)}')\n",
        "      print()\n",
        "\n",
        "      model.train()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "  avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "  training_time = format_time(time.time()-t0)\n",
        "  print(f'Average Training Loss: {avg_train_loss}. Epoch time: {training_time}')\n",
        "  print()\n",
        "\n",
        "  t0 = time.time()\n",
        "  model.eval()\n",
        "\n",
        "  total_eval_loss = 0\n",
        "  nb_eval_steps = 0\n",
        "\n",
        "  for batch in val_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_labels = batch[0].to(device)\n",
        "    b_masks = batch[1].to(device)\n",
        "        \n",
        "    with torch.no_grad():        \n",
        "\n",
        "        outputs  = model(b_input_ids,  \n",
        "                         attention_mask = b_masks,\n",
        "                         labels=b_labels)\n",
        "          \n",
        "        loss = outputs[0]  \n",
        "            \n",
        "    batch_loss = loss.item()\n",
        "    total_eval_loss += batch_loss   \n",
        "\n",
        "  avg_val_loss = total_eval_loss / len(val_dataloader)  \n",
        "  val_time = format_time(time.time() - t0)    \n",
        "  print(f'Validation loss: {avg_val_loss}. Validation Time: {val_time}')\n",
        "  print()\n",
        "\n",
        "  # Record all statistics from this epoch.\n",
        "  training_stats.append(\n",
        "      {\n",
        "          'epoch': epoch_i + 1,\n",
        "          'Training Loss': avg_train_loss,\n",
        "          'Valid. Loss': avg_val_loss,\n",
        "          'Training Time': training_time,\n",
        "          'Validation Time': val_time\n",
        "      }\n",
        "  )\n",
        "  print(\"------------------------------\")\n",
        "\n",
        "print(f'Total training took {format_time(time.time()-total_t0)}')"
      ],
      "id": "27453737"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc62c28a"
      },
      "outputs": [],
      "source": [],
      "id": "cc62c28a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "879a706a",
        "outputId": "befd9dd6-56a4-4588-c806-9163ec5f1849"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: the moon came late to a lonesome bog\n",
            "and there sat gluck a frog\n",
            "slowly winding up its string.\n",
            "\n",
            "\n",
            "1: autumn deepens <>\n",
            "your voice sweet\n",
            "scent of cedar.\n",
            "\n",
            "\n",
            "2: myr\n",
            "to bear forgiving and forgiven you both must go\n",
            "before you part again from me.\n",
            "\n",
            "\n",
            "3: spring mist\n",
            "I trace my toe\n",
            "into a peach.\n",
            "\n",
            "\n",
            "4: i was the babbitt metal of the future\n",
            "i forged my way in afterglow\n",
            "into flesh of contention and pebble.\n",
            "\n",
            "\n",
            "5: autumn leaves\n",
            "a single magpie\n",
            "in the sky.\n",
            "\n",
            "\n",
            "6: and when they arrive they are\n",
            "just plain scrambled eggs and the warm weather\n",
            "is holding.\n",
            "\n",
            "\n",
            "7: and when i lifted my eyes to your name\n",
            "and as i led your to the door\n",
            "i saw the path you made.\n",
            "\n",
            "\n",
            "8: the last light\n",
            "of the day's sunset\n",
            "crescent moon.\n",
            "\n",
            "\n",
            "9: winter moon \n",
            "a woman with silver hair\n",
            "steps back into a car.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=20, \n",
        "                                max_length = 40,\n",
        "                                top_p=0.8, \n",
        "                                num_return_sequences=10\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "id": "879a706a"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9TKves6f8c2",
        "outputId": "d25be34d-e5e2-4d90-91ec-5f22899b3775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: distant thunder \n",
            "a white butterfly follows\n",
            "the train line.\n",
            "\n",
            "\n",
            "1: the wayfarers bared their brow\n",
            "pierced their pashto prayers\n",
            "and made their study so full\n",
            "\n",
            "\n",
            "2: the smell\n",
            "of cooking\n",
            "from somewhere else.\n",
            "\n",
            "\n",
            "3: spring cleaning \n",
            "the house fills with\n",
            "diminutive eggs.\n",
            "\n",
            "\n",
            "4: spring rain\n",
            "a few blocks closer\n",
            "than yesterday.\n",
            "\n",
            "\n",
            "5: in a pile of rubble\n",
            "the colors are great\n",
            "guitar and harmonica.\n",
            "\n",
            "\n",
            "6: i know you like to think\n",
            "i know you like to think\n",
            "but i'm not myself.\n",
            "\n",
            "\n",
            "7: what do you want with that long black hair\n",
            "long fingernails long fingernails\n",
            "long fingernails.\n",
            "\n",
            "\n",
            "8: a long night \n",
            "the silence\n",
            "of the garden.\n",
            "\n",
            "\n",
            "9: a few leaves remain\n",
            "the remaining three are curled apart\n",
            "and curled apart.\n",
            "\n",
            "\n",
            "10: autumn sun\n",
            "the smell of fresh rain\n",
            "in her thighs.\n",
            "\n",
            "\n",
            "11: and they all fit\n",
            "into one big bowl\n",
            "and the spoons one by one.\n",
            "\n",
            "\n",
            "12: the sound of the rain\n",
            "in every room\n",
            "winter solstice.\n",
            "\n",
            "\n",
            "13: spring cleaning \n",
            "the old gate sags\n",
            "into its shadow.\n",
            "\n",
            "\n",
            "14: and this gulf of blues deep and shiny\n",
            "billowing across the water\n",
            "billowing toward the stars.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=30, \n",
        "                                max_length = 25,\n",
        "                                top_p=0.7, \n",
        "                                num_return_sequences=15\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "id": "O9TKves6f8c2"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21dQszhsf-4m",
        "outputId": "171345f6-f8ea-463f-d949-2e3ce3addc1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: a dog stares\n",
            "his cataract eyes\n",
            "the colour of moons\n",
            "\n",
            "\n",
            "1: myr\n",
            "'tis fired when i die\n",
            "i will not be\n",
            "\n",
            "\n",
            "2: i'm not in with this mystery\n",
            "hellhound's got it all\n",
            "\n",
            "\n",
            "3: spring rain\n",
            "the old rubber boots\n",
            "slip.\n",
            "\n",
            "\n",
            "4: the sun came miss brooks\n",
            "in high noon\n",
            "suddenly the\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<|startoftext|>\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                do_sample=True,   \n",
        "                                top_k=20, \n",
        "                                max_length = 15,\n",
        "                                top_p=0.5, \n",
        "                                num_return_sequences=5\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "id": "21dQszhsf-4m"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e9bca485",
        "outputId": "05fc0ab9-719b-4108-debb-1a0187832161"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/gdrive/MyDrive/Work/GPTmodels/GPT2Tuned/tokenizer_config.json',\n",
              " '/content/gdrive/MyDrive/Work/GPTmodels/GPT2Tuned/special_tokens_map.json',\n",
              " '/content/gdrive/MyDrive/Work/GPTmodels/GPT2Tuned/vocab.json',\n",
              " '/content/gdrive/MyDrive/Work/GPTmodels/GPT2Tuned/merges.txt',\n",
              " '/content/gdrive/MyDrive/Work/GPTmodels/GPT2Tuned/added_tokens.json')"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_dir = \"/content/gdrive/MyDrive/Work/GPTmodels/GPT2Tuned\"\n",
        "\n",
        "# Save generated poems\n",
        "# sample_outputs = model.generate(\n",
        "#                                 generated, \n",
        "#                                 do_sample=True,   \n",
        "#                                 top_k=50, \n",
        "#                                 max_length = 300,\n",
        "#                                 top_p=0.95, \n",
        "#                                 num_return_sequences=25\n",
        "#                                 )\n",
        "\n",
        "# with open(os.path.join(output_dir, 'generated_poems.txt'), \"w\") as outfile:\n",
        "#   for i, sample_output in enumerate(sample_outputs):\n",
        "#     outfile.write(tokenizer.decode(sample_output, skip_special_tokens=True)+\"\\n\\n\")\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(training_stats, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "id": "e9bca485"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "12f9f246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4687124-efc2-418c-9ada-99e2e315c595"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50259, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Loading saved model\n",
        "model_dir = \"/content/gdrive/MyDrive/Work/GPTmodels/GPT2Tuned\"\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# model = GPT2LMHeadModel.from_pretrained(\"prajwalcr/poetry-joy_gpt2\")\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(\"prajwalcr/poetry-joy_gpt2\")\n",
        "model.to(device)"
      ],
      "id": "12f9f246"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}